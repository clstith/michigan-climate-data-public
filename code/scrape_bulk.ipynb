{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is to scrape all data I plan to visualize from the NOAA API. This will let me consolidate the files instead of having different CSVs and scraping scripts for each type of measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from my_api_info import get_noaa_token\n",
    "from time import sleep\n",
    "from MI_info import stationids_to_FIPS, FIPS_to_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_data(YYYY_MM: str) -> requests.models.Response:\n",
    "    \"\"\"\n",
    "    Given an input string representing a month (in the format \n",
    "    YYYY-MM, e.g. '2024-01' for January of 2024), returns Response\n",
    "    from NOAA API with desired monthly data for each MI station.\n",
    "    \"\"\"\n",
    "    # Desired date range\n",
    "    start_date = YYYY_MM + '-01'\n",
    "\n",
    "    # API specifications\n",
    "    base_url = 'https://www.ncei.noaa.gov/cdo-web/api/v2'\n",
    "    extension = '/data'\n",
    "    url = base_url + extension\n",
    "\n",
    "    headers = {'token':get_noaa_token()}\n",
    "    parameters = {'datasetid':'GSOM',\n",
    "                'startdate':start_date,\n",
    "                'enddate':start_date,\n",
    "                'units':'metric',\n",
    "                'datatypeid':'PRCP,SNOW,TMIN,TMAX',\n",
    "                'station':'GHCND:US',\n",
    "                'locationid':'FIPS:' + '26',\n",
    "                'limit':1000,\n",
    "                'includemetadata':'false'}\n",
    "    r = requests.get(url,\n",
    "                    headers=headers,\n",
    "                    params=parameters)\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master DataFrame \n",
    "master_df = pd.DataFrame(\n",
    "    [],\n",
    "    columns=['station', 'FIPS', 'county_name',\n",
    "              'date', 'data_type', 'value']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for adding requested JSON data to DataFrame\n",
    "def add_data(r: requests.models.Response, start_idx: int) -> None:\n",
    "    \"\"\"\n",
    "    Adds json data from r to master_df. start_idx offests \n",
    "    addition so that we don't overwrite previous data\n",
    "    \"\"\"\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame.from_dict(r.json()['results'])\n",
    "    df = df.drop(['attributes'], axis=1)\n",
    "    # Add DataFrame to master_df \n",
    "    for i in df.index:\n",
    "        i_ = start_idx + i\n",
    "        station = df.loc[i, 'station']\n",
    "        date = df.loc[i, 'date']\n",
    "        data_type = df.loc[i, 'datatype']\n",
    "        value = df.loc[i, 'value']\n",
    "        try: \n",
    "            _, station = station.split(':')\n",
    "            fips = stationids_to_FIPS[station]\n",
    "            county_name = FIPS_to_county['0' + str(fips)]\n",
    "        except KeyError:\n",
    "            fips = np.nan\n",
    "            county_name = 'NO FIPS'\n",
    "        master_df.loc[i_,'station'] = df.loc[i, 'station']\n",
    "        master_df.loc[i_, 'FIPS'] = fips \n",
    "        master_df.loc[i_, 'data_type'] = data_type\n",
    "        master_df.loc[i_, 'county_name'] = county_name\n",
    "        master_df.loc[i_, 'date'] = date\n",
    "        master_df.loc[i_, 'value'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main scraping loop to scrape 10 years at a time (this seems like\n",
    "# a reasonable range). Modify the starting segment of the YYYY and\n",
    "# the range.\n",
    "\n",
    "# I learned the hard way that this code is really inefficient; \n",
    "# using loc to insert is a very inefficient way of adding to a \n",
    "# pandas DataFrame. Better would be to use concat, and better than \n",
    "# that would be to insert data into a dict and then at the end \n",
    "# create a DataFrame from this dict. \n",
    "\n",
    "for j in range(20, 24): # year loop\n",
    "    YYYY = '20' + str(j)\n",
    "    for i in range(1, 13): # month loop\n",
    "        print(f'Working on Year {YYYY}, Month {i}')\n",
    "        # NOAA API requests limited to 5 per second; \n",
    "        # I'm just being cautious here\n",
    "        sleep(1.5)\n",
    "        if i < 10: \n",
    "            MM = '0' + str(i)\n",
    "        else: \n",
    "            MM = str(i)\n",
    "        YYYY_MM = YYYY + '-' + MM\n",
    "        try: r = get_month_data(YYYY_MM)\n",
    "        except TimeoutError: \n",
    "            sleep(5)\n",
    "            r = get_month_data(YYYY_MM)\n",
    "        status_code = r.status_code\n",
    "\n",
    "        if status_code == 200: # Make sure request succeeded\n",
    "            add_data(r, len(master_df))\n",
    "        \n",
    "        else: # If there was an error accessing the API \n",
    "            print(f'Retrying Year {YYYY} Month {MM}')\n",
    "            sleep(5)\n",
    "            try: r = get_month_data(YYYY_MM)\n",
    "            except TimeoutError: \n",
    "                sleep(5)\n",
    "                r = get_month_data(YYYY_MM)\n",
    "            status_code = r.status_code \n",
    "            print(f'Year {YYYY} Month {i} status: {status_code}')\n",
    "            if status_code == 200: \n",
    "                add_data(r, len(master_df))\n",
    "            else: # If it fails again, try one more time with long pause\n",
    "                print(f'Retrying again...')\n",
    "                sleep(10)\n",
    "                try: r = get_month_data(YYYY_MM)\n",
    "                except TimeoutError: \n",
    "                    sleep(5)\n",
    "                    r = get_month_data(YYYY_MM)\n",
    "                status_code = r.status_code\n",
    "                print(f'Year {YYYY} Month {i} status: {status_code}')\n",
    "                if status_code == 200:\n",
    "                    add_data(r, len(master_df))\n",
    "                else: # Third time it fails, give up \n",
    "                    print(f'**************** Failed for Year {YYYY} Month {MM} :( ****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final DataFrame\n",
    "master_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save as CSV\n",
    "#master_df.to_csv('../data/bulk_data/2020-2023_bulk.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
