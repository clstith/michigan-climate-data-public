{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a file to clean the CSV files scraped from the NOAA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from MI_info import stationids_to_FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw data we want to clean\n",
    "file_name = 'file_name_goes_here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df = df.set_index('station')\n",
    "df.columns.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_exist = False\n",
    "for i in df.index.duplicated():\n",
    "    if i: \n",
    "        duplicates_exist = True \n",
    "print(f'duplicates_exist: {duplicates_exist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a county-level rainfall CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in df.index:\n",
    "    try: \n",
    "        prefix, station = station.split(':')\n",
    "        fips = stationids_to_FIPS[station]\n",
    "    except KeyError: \n",
    "        fips = np.nan\n",
    "    df.loc[prefix + ':' + station, 'FIPS'] = fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns so that FIPS is first \n",
    "col = df.columns\n",
    "col = col[:-1]\n",
    "col = col.insert(0, 'FIPS')\n",
    "df = df[col]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many stations do not have an assigned FIPS? \n",
    "num_unassigned = len([x for x in df.FIPS.notna() if x == False])\n",
    "print(f'There are {num_unassigned} stations with no FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fips = df[df['FIPS'].notna()].set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs say that mean() skips NaN values by default\n",
    "df_fips_mean = df_fips.groupby(['FIPS']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give column headers the appropriate datetime format\n",
    "df_fips_mean.columns = pd.to_datetime(df_fips_mean.columns)\n",
    "df_fips_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save as CSV\n",
    "fips_file_name_1 = file_name.split('.')[0] + '_FIPS.csv'\n",
    "df_fips_mean.to_csv(fips_file_name_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to mess around with the DataFrame until it becomes an easy-to-use format for Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reformatted = pd.DataFrame(df_fips_mean.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for code in df_fips_mean.index:\n",
    "    print(\"Working on FIPS code:\", code)\n",
    "    for date in df_fips_mean.columns:\n",
    "        new_df.loc[i, 'FIPS'] = code\n",
    "        new_df.loc[i, 'date'] = date \n",
    "        date_str = str(date).split(' ')[0]\n",
    "        new_df.loc[i, 'rainfall'] = df_fips_mean.loc[code, date_str]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['FIPS'] = new_df['FIPS'].apply(np.int64).apply(str)\n",
    "new_df.index.name = 'row_no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to save as CSV\n",
    "# fips_file_name_2 = file_name.split('.')[0] + '_alt_formatting.csv'\n",
    "# new_df.to_csv(fips_file_name_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
