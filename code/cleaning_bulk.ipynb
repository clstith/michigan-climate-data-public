{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning below for the bulk data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of decimals in FIPS \n",
    "p = Path('../data/bulk_data/1900-2023_bulk.csv')\n",
    "df = pd.read_csv(p)\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of NaNs in df \n",
    "a = [x for x in df['FIPS'].isna() if x == True]\n",
    "print(f'There are {len(a)} NaNs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are so few (relative to the 700k - that's \n",
    "# less than .6% of the rows) we will drop them \n",
    "df = df[df['FIPS'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to cast the FIPS column as integers \n",
    "df['FIPS'] = df['FIPS'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.read_csv('../data/bulk_data/1900-2023_bulk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = compare_df[compare_df['FIPS'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = compare_df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is empty, which is good\n",
    "[x for x in compare_df['value'] == df['value'] if x == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save as CSV\n",
    "#df.to_csv('data/bulk_data/1900-2023_bulk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for cut-off years/months during scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bulk_data/2010-2019_bulk.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The limit for the API requests was 1000 per each month,\n",
    "# so let's check we didn't get cut off\n",
    "for i in range(10, 20):\n",
    "    YYYY = '20' + str(i)\n",
    "    for j in range(1, 13):\n",
    "        if j < 10: MM = '0' + str(j)\n",
    "        else: MM = str(j)\n",
    "        date_str = '-'.join([YYYY,MM]) + '-01T00:00:00'\n",
    "        length = len(df[df.date == date_str])\n",
    "        if length >= 1000: \n",
    "            print(YYYY, MM, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The limit for the API requests was 1000 per each month,\n",
    "# so let's check we didn't get cut off\n",
    "df2 = pd.read_csv('../data/bulk_data/2020-2023_bulk.csv')\n",
    "for i in range(10, 20):\n",
    "    YYYY = '20' + str(i)\n",
    "    for j in range(1, 13):\n",
    "        if j < 10: MM = '0' + str(j)\n",
    "        else: MM = str(j)\n",
    "        date_str = '-'.join([YYYY,MM]) + '-01T00:00:00'\n",
    "        length = len(df2[df2.date == date_str])\n",
    "        if length >= 1000: \n",
    "            print(YYYY, MM, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So only the 2010-2020 CSV has potential cutoffs, and only for June and August of 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's concatenate the data into one CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = [x for x in Path('../data/bulk_data').iterdir()]\n",
    "dfs = [pd.read_csv(csv) for csv in csvs]\n",
    "dfs = list(map(lambda a : a.drop('Unnamed: 0', axis=1) , dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df is the full concatenated DataFrame\n",
    "master_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save as CSV\n",
    "#master_df.to_csv('data/bulk_data/1900-2023_bulk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
